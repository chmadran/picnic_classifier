{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICNIC CLASSIFIER\n",
    "\n",
    "Build a simple text classification prototype that predicts a category for short text snippets such as webpage titles, article headlines, or sentences. Example categories: sports, finance, fashion, technology (or any 4–6 you choose).\n",
    "\n",
    "NB : I did not build this pipeline with space/time complexity in mind as im completing some extra steps (e.g sorting in place etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import load_vectorizer, load_model, predict_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL_OPTIONS = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "\n",
    "MODEL = \"Logistic Regression\"\n",
    "VECTORIZATION_METHOD = \"TF-IDF\"\n",
    "LABELS = ['comp.sys.mac.hardware', 'rec.autos', 'sci.space', 'talk.politics.guns']\n",
    "LABELS.sort()\n",
    "REMOVE = ('headers', 'footers', 'quotes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 : Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=LABELS, remove=REMOVE)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=LABELS, remove=REMOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(newsgroups_train.data)\n",
    "len_test = len(newsgroups_test.data)\n",
    "len_total = len_train + len_test\n",
    "\n",
    "print(f\"For {len_total} documents in total, there are {len_train} docs in train ({(len_train / len_total) * 100:0.0f}%) and {len_test} ({(len_test / len_total) * 100:0.0f}%) docs in test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Labels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(newsgroups_train.target_names):\n",
    "    print(f\"{i} : {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Text</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((newsgroups_train.data[0][:600].strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : Pre process the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to feed models with the text data, we need to **turn the text into vectors of numerical values** first. One vectorizer we can use is the built in TF-IDF sklearn one which is a statistical method used in nlp to evaluate how important a word is to a document in relation to its corpus. TF-IDF combines two components:\n",
    "\n",
    "* TF (Term Frequency): count of n words in doc / total nb words in doc\n",
    "* IDF (Inverse Document Frequency): rarity of a term across a collection of documents to penalize common words (log(total nb docs / 1 + (in case 0) nb docs with the term))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = load_vectorizer(VECTORIZATION_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the vocabulary\n",
    "vectors_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "\n",
    "#only convert into vectors\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 : Load and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use a simple logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL)\n",
    "\n",
    "#find the optimal parameter of our regression\n",
    "model.fit(vectors_train, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 : Predict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Get predictions</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(vectors_test)\n",
    "# print(probs[0])\n",
    "\n",
    "preds = model.predict(vectors_test)\n",
    "# print(preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Metrics</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 : {metrics.f1_score(newsgroups_test.target, preds, average=\"macro\"):0.2f}\")\n",
    "print(f\"Accuracy : {metrics.accuracy_score(newsgroups_test.target, preds):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Confusion Matrix</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(newsgroups_test.target, preds)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=LABELS)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
    "plt.title(\"v0 results\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you'd like to try !\n",
    "\n",
    "The playground is where you can either use some of the example prompts I got from Claude or insert your own to try out the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = {\n",
    "    \"comp.sys.mac.hardware\": [\n",
    "        \"My old PowerBook won’t recognize the new external SCSI drive.\",\n",
    "        \"Thanks everyone — the issue was with the Mac’s RAM card, replaced it and it boots fine!\"\n",
    "    ],\n",
    "    \"rec.autos\": [\n",
    "        \"Just got a new Honda Civic — love how smooth the engine feels.\",\n",
    "        \"My transmission is making a strange noise when shifting gears — could it be low fluid?\"\n",
    "    ],\n",
    "    \"sci.space\": [\n",
    "        \"How does NASA plan to maintain communication with spacecraft beyond Mars orbit?\",\n",
    "        \"SpaceX successfully launched another batch of Starlink satellites today.\"\n",
    "    ],\n",
    "    \"talk.politics.guns\": [\n",
    "        \"The new firearm control bill just passed — what does this mean for gun owners?\",\n",
    "        \"FBI reports show a rise in illegal weapon sales — stricter enforcement might help.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_texts = [text for texts in examples.values() for text in texts]\n",
    "# one_text = examples[\"sci.space\"][0]\n",
    "random_text = \"Hello I'm computer Charlotte a brand new car, i have 5 seats.\"\n",
    "predict_text(random_text, model, vectorizer, LABELS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "picnic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
